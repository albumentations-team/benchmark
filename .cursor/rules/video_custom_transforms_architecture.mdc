---
description: Architecture of the video benchmark system — how video transform spec files work, what VideoBenchmarkRunner expects, and library-specific calling conventions.
globs: benchmark/video_runner.py, benchmark/transforms/**/*video*.py, run_video_single.sh, run_video_all.sh, examples/*video*.py
alwaysApply: false
---

# Video Benchmark Architecture

## Transform Spec File Contract

Every spec file (built-in or custom) must define three things at module level:

```python
LIBRARY = "albumentationsx"  # controls which venv/requirements are used

def __call__(transform: Any, video: Any) -> Any:  # noqa: N807
    """Called once per video during benchmarking."""
    result = transform(images=video)["images"]
    return np.ascontiguousarray(result)

TRANSFORMS = [
    {"name": "HorizontalFlip", "transform": A.HorizontalFlip(p=1)},
]
```

Key details:
- `__call__` receives **a single video** (not batched) — the runner loops over videos itself
- Video shape is `(T, H, W, C)` for numpy-based libraries (AlbumentationsX)
- Video shape is `(T, C, H, W)` for tensor-based libraries (torchvision, Kornia)
- `name` appears verbatim in result JSON keys and comparison tables
- All transforms must have `p=1` for deterministic benchmarking
- The module is validated by `load_from_python_file()` in `benchmark/video_runner.py`

## VideoBenchmarkRunner (`benchmark/video_runner.py`)

```python
VideoBenchmarkRunner(
    library=library,        # str, used for video loader and GPU handling
    data_dir=data_dir,      # Path, searched recursively for .mp4/.avi/.mov
    transforms=transforms,  # list[{"name": str, "transform": Any}]
    call_fn=call_fn,        # the __call__ function from spec file
    num_videos=50,
    num_runs=5,
    max_warmup_iterations=100,
    warmup_window=5,
    warmup_threshold=0.05,
    min_warmup_windows=3,
)
```

Warmup early-stops if:
- `time_per_video > 2.0` sec (after 5+ iterations)
- total warmup time > 120 sec

Videos are pre-loaded into memory (GPU if available for tensor libraries). For Kornia, videos are kept as `float16` on GPU.

## Built-in vs Custom Transform Files

**Built-in** (`benchmark/transforms/*_video_impl.py`):
- Import `TRANSFORM_SPECS` from `benchmark/transforms/specs.py`
- Use a `create_transform(spec)` factory for shared spec → library transform mapping
- Ensures all libraries benchmark the same operations for fair comparison

**Custom** (user files, e.g. `examples/custom_video_specs_template.py`):
- Define `TRANSFORMS` directly with arbitrary transform instances
- Full control over parameters; useful for parametric testing

```bash
# Built-in
./run_video_single.sh -d /videos -o output/albumentationsx_results.json \
  -s benchmark/transforms/albumentationsx_video_impl.py

# Custom
./run_video_single.sh -d /videos -o output/my_results.json -s my_transforms.py
```

## Video Loading

Videos are loaded via `get_video_loader(library)` from `benchmark/utils.py`. Files are discovered recursively (`.mp4`, `.avi`, `.mov`). For GPU libraries (kornia, torchvision), tensors are moved to device during loading, before benchmarking begins.

## Output Format

```json
{
  "metadata": {
    "system_info": {...},
    "library_versions": {...},
    "thread_settings": {"OMP_NUM_THREADS": "1", ...},
    "benchmark_params": {"num_videos": 50, "num_runs": 5, ...},
    "precision": "torch.float16"
  },
  "results": {
    "HorizontalFlip": {
      "supported": true,
      "median_throughput": 45.2,
      "std_throughput": 1.8,
      "warmup_iterations": 8,
      "variance_stable": true,
      "early_stopped": false,
      "early_stop_reason": null
    }
  }
}
```

`precision` field only present for tensor-based libraries.

## Library-specific `__call__` patterns

**AlbumentationsX** — numpy `(T, H, W, C)`, uses `images=` key:
```python
def __call__(transform, video):
    result = transform(images=video)["images"]
    return np.ascontiguousarray(result)
```

**torchvision** — tensor `(T, C, H, W)`, GPU if available:
```python
def __call__(transform, video):
    torch.manual_seed(42)
    if device.type == "cuda" and not isinstance(transform, v2.JPEG):
        video = (video.float() / 255.0).half()
    return transform(video).contiguous()
```

**Kornia** — tensor `(T, C, H, W)`, GPU float16, treats T as batch:
```python
def __call__(transform, video):
    if device.type == "cuda":
        video = video.half()
    # same_on_batch=True required for consistent transform across frames
    return transform(video)
```

Use `same_on_batch=True` on Kornia transforms so all frames get the same spatial transform.

## Differences from Image Benchmark

| Aspect | Video | Image |
|--------|-------|-------|
| `__call__` receives | single video `(T, H, W, C)` | single image |
| Slow threshold | 2.0 sec/video | 0.1 sec/image |
| Default num items | 50 videos | 2000 images |
| Warmup subset | 3 videos | 10 images |
| GPU support | yes (kornia, torchvision) | no |
| File discovery | recursive `.mp4/.avi/.mov` | flat dir glob |
| Extra libraries | — | imgaug, augly |
